{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2Model, GPT2Tokenizer\n",
    "model_file_path = \"C:/Users/Michael/Documents/Bangkit/Project Capstone/gpt2_saved_model.h5\"\n",
    "#Use Custom Objects if there is transfer learning\n",
    "model = tf.keras.models.load_model(model_file_path,\n",
    "                                      custom_objects={\n",
    "                                          \"TFGPT2Model\":TFGPT2Model\n",
    "                                      })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Set the tokenizer padder\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#breakdown articles/posts into sentence\n",
    "def post_to_sentences(posts):\n",
    "    sentence_list = []\n",
    "    for post in posts:\n",
    "        post = str(post)  # Convert paragraph to string\n",
    "        # Split text on whitespace after period or question mark,\n",
    "        # unless preceeded by single letter or followed by word character\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', post)\n",
    "        for sentence in sentences:\n",
    "            sentence_list.append(sentence) \n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question conscience goes beyond science']\n",
      "{'input_ids': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[25652, 18346,  2925,  3675,  3783]])>, 'attention_mask': <tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[1, 1, 1, 1, 1]])>}\n",
      "Predicted prob each sentence:  [[0.5426998  0.01140414 0.2646439  0.17572728 0.00552487]]\n",
      "Predicted prob:  [0.5426998  0.01140414 0.2646439  0.17572728 0.00552487]\n",
      "Predicted label: Gaming\n",
      "Predicted prob:  [[0.5426998  0.01140414 0.2646439  0.17572728 0.00552487]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#BUTUH PERBAIKAN\n",
    "#test inference\n",
    "example = \"question conscience goes beyond science\"\n",
    "#TODO:preprocess data, predict, then interpret\n",
    "example = post_to_sentences([example])\n",
    "print(example)\n",
    "tokenized_example = tokenizer(example, padding=True, truncation=True, max_length=100, return_tensors=\"tf\")\n",
    "print(tokenized_example)\n",
    "#make prediction\n",
    "example_ids = tokenized_example.input_ids\n",
    "example_attention_mask = tokenized_example.attention_mask\n",
    "predicted_probs = model([example_ids,example_attention_mask]) # pass both inputs here\n",
    "predicted_probs = predicted_probs.numpy()\n",
    "#logits = predicted_label.logits\n",
    "#predicted_label = tf.argmax(logits,axis=-1)\n",
    "# Map the predicted label index to the actual label\n",
    "#BUTUH PERBAIKAN, INI RASANYA ADA YANG SALAH\n",
    "\n",
    "#Untuk memproses multi- sentence\n",
    "sum_probs = np.sum(predicted_probs, axis=0)\n",
    "print(\"Predicted prob each sentence: \", predicted_probs)\n",
    "print(\"Predicted prob: \", sum_probs)\n",
    "#urutannya bener books cinema cooking gaming sport? soalnya kalo diacak predicted probnya tetep sama\n",
    "label_mapping = {0: 'Gaming', 1: 'Sports', 2: 'Cinema', 3: 'Books', 4: 'Cooking'}\n",
    "index = np.argmax(sum_probs)\n",
    "predicted_label = label_mapping[index]\n",
    "\n",
    "#Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)\n",
    "print(\"Predicted prob: \", predicted_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
